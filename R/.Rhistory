get_interactions <- function(CVDP){
for (i in 1:length(CVDP)){
print(CVDP[i])
pname <- paste(CVDP[i],'[sym]',sep="")
ids<-GetIDs(pname)
plist<-GetInteractions(ids)
plist<-unique(plist[13])
#print(plist)
cvd<-rep(CVDP[i],nrow(plist))
ptemp <- cbind(cvd,plist)
if(i!=1){
ppi <- rbind(ppi,ptemp)}
else{
ppi <- ptemp}
}
return(ppi)
}
# See how many research articles are written about our proteins. Uses rentrez package.
count_articles <- function (CVDP){
for (i in 1:length(CVDP)){
print(CVDP[i])
pname <- paste(CVDP[i],'[GENE]) AND (Homo sapiens[ORGN])',sep="")
ids<-entrez_search(db="pubmed", term=pname,retmax=40000)
atemp <- cbind(CVDP[i],length(ids$ids))
if(i!=1){
articles <- rbind(articles,atemp)}
else{
articles <- atemp}
}
return(articles)
}
# scrape the interaction table from the NCBI web page.
get.ppiNCBI <- function(g.n) {
require(XML)
ppi <- data.frame()
for(i in 1:length(g.n)){
o <- htmlParse(paste("http://www.ncbi.nlm.nih.gov/gene/", g.n[i], sep=''))
# check if interaction table exists
exist <- length(getNodeSet(o, "//table//th[@id='inter-prod']"))>0
if(exist){
p <- getNodeSet(o, "//table")
## need to know which table is the good one
for(j in 1:length(p)){
int <- readHTMLTable(p[[j]])
if(colnames(int)[2]=="Interactant"){break}
}
ppi <- rbind(ppi, data.frame(egID=g.n[i], intSymbol=int$`Other Gene`))
}
# play nice! and avoid being kicked out from NCBI servers
Sys.sleep(1)
}
if(dim(ppi)[1]>0){
ppi <- unique(ppi)
print(paste(dim(ppi)[1], "interactions found"))
return(ppi)
} else{
print("No interaction found")
}
# R provides a tail and head command to view last six and first six elements, so why not a middle?
middle <- function(mydata) {
len <- dim(mydata)
startpoint <- round(len[1]/2)
endpoint <- startpoint+6
mydata[startpoint:endpoint,]
}
install.packages("NCBI2R")
wb <- loadWorkbook("C://R-files//disease//stomachcancer_genealacart6-12-16.xlsx")
df <- readWorksheet(wb, sheet=3)
df
rm(wb,df)
entrez_db_searchable("omim")
?entrez_search
genelist <- bitr(Dproteins,fromType = "SYMBOL",toType="ENTREZID",OrgDb="org.Hs.eg.db")
genelist
genelist <- bitr(Dproteins,fromType = "SYMBOL",toType="ENTREZID",OrgDb="org.Hs.eg.db")
genelist <- genelist[2]
genelist <- sapply(genelist, as.character)
genelist <- as.character(unname(genelist, force = TRUE))
genelist<- as.character(genelist)
yy = enrichPathway(genelist, pvalueCutoff=0.1,organism="human",readable=TRUE)
head(yy)
tempcrap <- count_articles(Dproteins)
tempcrap
rm(tempcrap)
count_articles <- function (CVDP){
for (i in 1:length(CVDP)){
print(CVDP[i])
pname <- paste(CVDP[i],'[GENE]) AND (Homo sapiens[ORGN])',sep="")
ids<-entrez_search(db="pubmed", term=pname,retmax=80000)
atemp <- cbind(CVDP[i],length(ids$ids))
if(i!=1){
articles <- rbind(articles,atemp)}
else{
articles <- atemp}
}
return(articles)
}
tempcount <- count_articles(Dproteins)
tempcount
count_articles <- function (CVDP){
for (i in 1:length(CVDP)){
print(CVDP[i])
pname <- paste(CVDP[i],'[GENE]) AND (Homo sapiens[ORGN])',sep="")
ids<-entrez_search(db="pubmed", term=pname,retmax=100000)
atemp <- cbind(CVDP[i],length(ids$ids))
if(i!=1){
articles <- rbind(articles,atemp)}
else{
articles <- atemp}
}
return(articles)
}
tempcount <- count_articles(Dproteins)
count_articles <- function (CVDP){
for (i in 1:length(CVDP)){
print(CVDP[i])
pname <- paste(CVDP[i],'[GENE]) AND (Homo sapiens[ORGN])',sep="")
ids<-entrez_search(db="pubmed", term=pname,retmax=90000)
atemp <- cbind(CVDP[i],length(ids$ids))
if(i!=1){
articles <- rbind(articles,atemp)}
else{
articles <- atemp}
}
return(articles)
}
tempcount <- count_articles(Dproteins)
tempcount
source("http://bioconductor.org/biocLite.R")
biocLite("NCBI2R")
library(NCBI2R)
version
install.packages("C:/Temp/NCBI2R-master/NCBI2R-master.zip", repos = NULL, type = "win.binary")
library(NCBI2R)
install.packages("C:/Temp/NCBI2R_1.4.7.tar.gz", repos = NULL, type = "source")
library(NCBI2R)
tempinteractions <- get_interactions(Dproteins)
tempinteractions
tempintcount <- count_interactions(Dproteins)
tempintcount
temparticlecount <- count_articles(Dproteins) # how many articles written about these proteins?
tempinteractions <- get_interactions(Dproteins)
tempintcount <- count_interactions(Dproteins)
tempintcount
temparticlecount
tempcrap <- get.ppiNCBI(Dproteins)
nrow(mygenes)
middle <- function(mydata) {
len <- nrow(mydata)
startpoint <- round(len[1]/2)
endpoint <- startpoint+6
mydata[startpoint:endpoint,]
}
middle(mygenes)
middle(mappings)
middle(disgene)
middle(digestive)
middle <- function(mydata) {
len <- nrow(mydata)
startpoint <- round(len/2)
endpoint <- startpoint+6
mydata[startpoint:endpoint,]
}
middle(digestive)
middle <- function(mydata) {
len <- nrow(mydata)
startpoint <- round(len/2)
endpoint <- startpoint+5
mydata[startpoint:endpoint,]
}
middle(digestive)
save.image("C:/R-files/disease/GI-disease-Oct21st2017.RData")
library(foreign)
library(MASS)
library(ggplot2)
library(foreign)
library(MASS)
library(ggplot2)
dat <- read.dta("http://www.karlin.mff.cuni.cz/~pesta/prednasky/NMFM404/Data/nb_data.dta")
dat <- within(dat, {
prog <- factor(prog, levels = 1:3, labels = c("General", "Academic", "Vocational"))
id <- factor(id)
})
summary(dat)
head(dat)
ggplot(dat, aes(daysabs, fill = prog)) + geom_histogram(binwidth = 1)
+ facet_grid(prog ~ ., margins = TRUE, scales = "free")
ggplot(dat, aes(daysabs, fill = prog)) + geom_histogram(binwidth = 1)+ facet_grid(prog ~ ., margins = TRUE, scales = "free")
with(dat, tapply(daysabs, prog, function(x) {
sprintf("M (SD) = %1.2f (%1.2f)", mean(x), sd(x))
}))
summary(m1 <- glm.nb(daysabs ~ math + prog, data = dat))
m2 <- update(m1, . ~ . - prog)
anova(m1, m2)
m3 <- glm(daysabs ~ math + prog, family = "poisson", data = dat)
pchisq(2 * (logLik(m1) - logLik(m3)), df = 1, lower.tail = FALSE)
(est <- cbind(Estimate = coef(m1), confint(m1)))
exp(est)
newdata1 <- data.frame(math = mean(dat$math), prog = factor(1:3, levels = 1:3,
labels = levels(dat$prog)))
newdata1$phat <- predict(m1, newdata1, type = "response")
newdata1
newdata2 <- cbind(newdata2, predict(m1, newdata2, type = "link", se.fit=TRUE))
newdata2 <- within(newdata2, {
DaysAbsent <- exp(fit)
LL <- exp(fit - 1.96 * se.fit)
UL <- exp(fit + 1.96 * se.fit)
})
newdata2 <- data.frame(
math = rep(seq(from = min(dat$math), to = max(dat$math), length.out = 100), 3),
prog = factor(rep(1:3, each = 100), levels = 1:3, labels =
levels(dat$prog)))
newdata2 <- cbind(newdata2, predict(m1, newdata2, type = "link", se.fit=TRUE))
newdata2 <- within(newdata2, {
DaysAbsent <- exp(fit)
LL <- exp(fit - 1.96 * se.fit)
UL <- exp(fit + 1.96 * se.fit)
})
ggplot(newdata2, aes(math, DaysAbsent)) +
geom_ribbon(aes(ymin = LL, ymax = UL, fill = prog), alpha = .25) +
geom_line(aes(colour = prog), size = 2) +
labs(x = "Math Score", y = "Predicted Days Absent")
m3 <- glm(daysabs ~ math + prog, family = "poisson", data = dat)
pchisq(2 * (logLik(m1) - logLik(m3)), df = 1, lower.tail = FALSE)
m3
(est <- cbind(Estimate = coef(m1), confint(m1)))
exp(est)
save.image("C:/R-files/statistics/negbinomialreg.RData")
m1
?within
tail(dat)
head(newdata1)
head(newdata2)
install.packages("paxtoolsr")
source("http://bioconductor.org/biocLite.R")
biocLite("paxtoolsr")
library(paxtoolsr)
searchResults <- searchPc(q = "glycolysis", type = "pathway")
searchResults
head(searchResults)
xpathSApply(searchResults, "/searchResponse/searchHit/name", xmlValue)[1]
xpathSApply(searchResults, "/searchResponse/searchHit/name", xmlValue)[2]
xpathSApply(searchResults, "/searchResponse/searchHit/name", xmlValue)[3]
library(factoextra)
library(NbClust)
library(factoextra)
library(NbClust)
kruskal.test(y~A)
library(coin)
library(MASS)
?prop.test
deathsE1 <- 12
deathsE2 <- 7
LivebirthsE1 <-13884
LivebirthsE2 <-19835
E1 <- (deathsE1/LivebirthsE1) * 1000
E2 <- (deathsE2/LivebirthsE2) * 1000
prop.test(x = c(12, 7), n = c(13884, 19835),conf.level = 0.95, correct = FALSE,alternative = "greater")
E1
E2
calcOddsRatio <- function(mymatrix,alpha=0.05,referencerow=2,quiet=FALSE)
{
numrow <- nrow(mymatrix)
myrownames <- rownames(mymatrix)
for (i in 1:numrow)
{
rowname <- myrownames[i]
DiseaseUnexposed <- mymatrix[referencerow,1]
ControlUnexposed <- mymatrix[referencerow,2]
if (i != referencerow)
{
DiseaseExposed <- mymatrix[i,1]
ControlExposed <- mymatrix[i,2]
totExposed <- DiseaseExposed + ControlExposed
totUnexposed <- DiseaseUnexposed + ControlUnexposed
probDiseaseGivenExposed <- DiseaseExposed/totExposed
probDiseaseGivenUnexposed <- DiseaseUnexposed/totUnexposed
probControlGivenExposed <- ControlExposed/totExposed
probControlGivenUnexposed <- ControlUnexposed/totUnexposed
# calculate the odds ratio
oddsRatio <- (probDiseaseGivenExposed*probControlGivenUnexposed)/
(probControlGivenExposed*probDiseaseGivenUnexposed)
if (quiet == FALSE)
{
print(paste("category =", rowname, ", odds ratio = ",oddsRatio))
}
# calculate a confidence interval
confidenceLevel <- (1 - alpha)*100
sigma <- sqrt((1/DiseaseExposed)+(1/ControlExposed)+
(1/DiseaseUnexposed)+(1/ControlUnexposed))
# sigma is the standard error of our estimate of the log of the odds ratio
z <- qnorm(1-(alpha/2))
lowervalue <- oddsRatio * exp(-z * sigma)
uppervalue <- oddsRatio * exp( z * sigma)
if (quiet == FALSE)
{
print(paste("category =", rowname, ", ", confidenceLevel,
"% confidence interval = [",lowervalue,",",uppervalue,"]"))
}
if (quiet == TRUE && numrow == 2) # If there are just two treatments (exposed/nonexposed)
{
return(oddsRatio)
}
mymatrix <- matrix(c(12,7,13884,19835),nrow=2,byrow=TRUE)
colnames(mymatrix) <- c("Disease","Control")
rownames(mymatrix) <- c("Exposed","Unexposed")
print(mymatrix)
mymatrix <- matrix(c(12,7,13884,19835),nrow=2,byrow=TRUE)
colnames(mymatrix) <- c("Epoch1","Epoch2")
rownames(mymatrix) <- c("Deaths","Livebirths")
print(mymatrix)
calcOddsRatio(mymatrix,alpha=0.05)
calcRelativeRisk <- function(mymatrix,alpha=0.05,referencerow=2)
{
numrow <- nrow(mymatrix)
myrownames <- rownames(mymatrix)
for (i in 1:numrow)
{
rowname <- myrownames[i]
DiseaseUnexposed <- mymatrix[referencerow,1]
ControlUnexposed <- mymatrix[referencerow,2]
if (i != referencerow)
{
DiseaseExposed <- mymatrix[i,1]
ControlExposed <- mymatrix[i,2]
totExposed <- DiseaseExposed + ControlExposed
totUnexposed <- DiseaseUnexposed + ControlUnexposed
probDiseaseGivenExposed <- DiseaseExposed/totExposed
probDiseaseGivenUnexposed <- DiseaseUnexposed/totUnexposed
# calculate the relative risk
relativeRisk <- probDiseaseGivenExposed/probDiseaseGivenUnexposed
print(paste("category =", rowname, ", relative risk = ",relativeRisk))
# calculate a confidence interval
confidenceLevel <- (1 - alpha)*100
sigma <- sqrt((1/DiseaseExposed) - (1/totExposed) +
(1/DiseaseUnexposed) - (1/totUnexposed))
# sigma is the standard error of estimate of log of relative risk
z <- qnorm(1-(alpha/2))
lowervalue <- relativeRisk * exp(-z * sigma)
uppervalue <- relativeRisk * exp( z * sigma)
print(paste("category =", rowname, ", ", confidenceLevel,
"% confidence interval = [",lowervalue,",",uppervalue,"]"))
}
calcRelativeRisk(mymatrix,alpha=0.05)
calcOddsRatio(mymatrix,alpha=0.05)
setwd("C:/R-files/BPS102")
data1 <- read.table('chestsizes.csv',header=TRUE,sep=',')
head(data1)
?aov
results <- aov(chestsize ~ activity, data=data1)
results
summary(results)
results <- aov(activity ~ chestsize, data=data1)
summary(results)
results <- aov(chestsize ~ activity, data=data1)
summary(results)
data1
results <- aov(chestsize ~ activity, data=data1)  # conduct the one-way anova
summary(results)
TukeyHSD(results, "tension", ordered = TRUE)
plot(TukeyHSD(results, "tension"))
TukeyHSD(results, "chestsize", ordered = TRUE)
results <- aov(chestsize ~ activity, data=data1)  # conduct the one-way anova
summary(results)
TukeyHSD(results, "chestsize", ordered = TRUE)
TukeyHSD(results, "activity", ordered = TRUE)
aov.results <- aov(chestsize ~ activity, data=data1)  # conduct the one-way anova
summary(aov.results)
TukeyHSD(aov.results, "activity", ordered = TRUE)
data1$activity <- as.factor(data1$activity)
aov.results <- aov(chestsize ~ activity, data=data1)  # conduct the one-way anova
summary(aov.results)
TukeyHSD(aov.results, "activity", ordered = TRUE)
plot(TukeyHSD(aov.results, "activity"))
boxplot(chestsize~acivity,data=data1)
boxplot(chestsize~activity,data=data1)
str(data1)
prop.test(x = c(12, 7), n = c(13884, 19835),conf.level = 0.95, correct = FALSE,alternative = "greater")
?prop.test
.000864-0.000352
TukeyHSD(aov.results, "activity", ordered = TRUE)
data2 <- read.table('worms.csv',header=TRUE,sep=',')
head(data2)
str(data2)
data2$activity <- as.factor(data2$activity)  # anova needs "fact
data2$Drug <- as.factor(data2$Drug)  # ano
data2 <- read.table('worms.csv',header=TRUE,sep=',')
head(data2)
str(data2)
data2$Drug <- as.factor(data2$Drug)
str(data2)
data2$Drug <- as.factor(data2$Drug)  # anova needs "factor" type data
aov.results <- aov(chestsize ~ activity, data=data2)  # conduct the one-way anova
summary(aov.results)
TukeyHSD(aov.results, "activity", ordered = TRUE)
boxplot(chestsize~activity,data=data2)
data2$Drug <- as.factor(data2$Drug)  # anova needs "factor" type data
aov.results <- aov(NumWorms ~ Drug, data=data2)  # conduct the one-way anova
summary(aov.results)
head(data2)
data2 <- read.table('worms.csv',header=TRUE,sep=',')
head(data2)
str(data2)
head(data2)
data2$Drug <- as.factor(data2$Drug)  # anova needs "factor" type data
aov.results <- aov(NumWorms ~ Drug, data=data2)  # conduct the one-way anova
summary(aov.results)
TukeyHSD(aov.results, "activity", ordered = TRUE)
boxplot(NumWorms~Drug,data=data2)
TukeyHSD(aov.results, "Drug", ordered = TRUE)
boxplot(NumWorms~Drug,data=data2)
table(mean(NumWorms~Drug))
aggregate(chestsize ~ activity, data=data1,fun= mean )
aggregate(chestsize ~ activity, data=data1,mean )
?aggregate
aggregate(chestsize ~ activity, data=data1, sd)   # get the m
aggregate(NumWorms ~ Drug, data=data2, mean)   # get the means of the groups
aggregate(NumWorms ~ Drug, data=data2, sd)   # get the standard deviations of the groups
data1 <- read.table('chestsizes.csv',header=TRUE,sep=',')
head(data1)
str(data1)
data1$activity <- as.factor(data1$activity)  # anova needs "factor" type data
str(data1)
aov.results <- aov(chestsize ~ activity, data=data1)  # conduct the one-way anova
summary(aov.results)
TukeyHSD(aov.results, "activity", ordered = TRUE)
boxplot(chestsize~activity,data=data1)
boxplot(chestsize~activity,data=data1,ylab="Chestsizes")
boxplot(chestsize~activity,data=data1,ylab="Chestsizes",xlab="activity")
aggregate(chestsize ~ activity, data=data1, mean)   # get the means of the groups
aggregate(chestsize ~ activity, data=data1, sd)   # get the standard deviations of the groups
memory.limit(2210241024*1024) # use more RAM memory (22 GBs)
setwd("C:/R-files/complexnetworks")    # point to where my code lives
load("complexnets_29thJan2018.RData")
source("complex_networks_functions.R")  #
plot_power2(gppi)
library(e1071)
day = c(0,1,2,3,4,5,6)
weather = c(1,0,0,0,0,0,0)
happy = factor(c(T,F,F,F,F,F,F))
d = data.frame(day=day, weather=weather, happy=happy)
model = svm(happy ~ day + weather, data = d)
plot(model, d)
d
summary(model)
x=c(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20)
y=c(3,4,5,4,8,10,10,11,14,20,23,24,32,34,35,37,42,48,53,60)
train=data.frame(x,y)
head(train)
plot(train,pch=16)
model_svm <- svm(y ~ x , train)
#Use the predictions on the data
pred <- predict(model_svm, train)
#Plot the predictions and the plot to see our model fit
points(train$x, pred, col = "blue", pch=4)
pred
summary(model_svm)
abline(model)
x=c(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20)
y=c(3,4,5,4,8,10,10,11,14,20,23,24,32,34,35,37,42,48,53,60)
#Create a data frame of the data
train=data.frame(x,y)
#Plot the dataset
plot(train,pch=16)
#Linear regression
model <- lm(y ~ x, train)
#Plot the model using abline
abline(model)
#SVM
library(e1071)
#Fit a model. The function syntax is very similar to lm function
model_svm <- svm(y ~ x , train)
#Use the predictions on the data
pred <- predict(model_svm, train)
#Plot the predictions and the plot to see our model fit
points(train$x, pred, col = "blue", pch=4)
#Linear model has a residuals part which we can extract and directly calculate rmse
error <- model$residuals
lm_error <- sqrt(mean(error^2)) # 3.832974
#For svm, we have to manually calculate the difference between actual values (train$y) with our predictions (pred)
error_2 <- train$y - pred
svm_error <- sqrt(mean(error_2^2)) # 2.696281
# perform a grid search
svm_tune <- tune(svm, y ~ x, data = train,
ranges = list(epsilon = seq(0,1,0.01), cost = 2^(2:9))
)
print(svm_tune)
#Parameter tuning of ‘svm’:
# - sampling method: 10-fold cross validation
#- best parameters:
# epsilon cost
#0 8
#- best performance: 2.872047
#The best model
best_mod <- svm_tune$best.model
best_mod_pred <- predict(best_mod, train)
error_best_mod <- train$y - best_mod_pred
# this value can be different on your computer
# because the tune method randomly shuffles the data
best_mod_RMSE <- sqrt(mean(error_best_mod^2)) # 1.290738
plot(svm_tune)
plot(train,pch=16)
points(train$x, best_mod_pred, col = "blue", pch=4)
)
rm(shite)
pred
rm(model,model_svm)
rm(pred,svm_error)
rm(x,y,weather)
rm(pred,svm_error)
rm(pred,svm_tune)
bar_plot_gg2(hubtargetlist,2,"blue")  #
